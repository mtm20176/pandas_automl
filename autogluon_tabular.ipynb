{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>autogluon - automated machine learning open source from aws</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior to getting started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home page: https://autogluon.mxnet.io/index.html\n",
    "\n",
    "Installation steps: https://autogluon.mxnet.io/index.html#installation\n",
    "\n",
    "Sample Code page: https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon as ag\n",
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark dataset test - BANK CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./sets/bank_churn_train.csv | Columns = 14 / 14 | Rows = 9000 -> 9000\n",
      "Loaded data from: ./sets/bank_churn_test.csv | Columns = 14 / 14 | Rows = 1000 -> 1000\n"
     ]
    }
   ],
   "source": [
    "train_data = task.Dataset(file_path='./sets/bank_churn_train.csv')\n",
    "test_data = task.Dataset(file_path='./sets/bank_churn_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7142\n",
       "1    1858\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Exited\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     4498\n",
       "Spain      2253\n",
       "Germany    2249\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Geography\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37    437\n",
       "38    434\n",
       "35    425\n",
       "36    406\n",
       "34    404\n",
       "     ... \n",
       "78      2\n",
       "84      2\n",
       "88      1\n",
       "82      1\n",
       "85      1\n",
       "Name: Age, Length: 69, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      4897\n",
       "Female    4103\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250898.09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Balance\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Balance\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"CreditScore\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"CreditScore\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerId  CreditScore Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0  C_15654463          841   Male   34       4       0.00              2   \n",
      "1  C_15791867          544   Male   44       2  108895.93              1   \n",
      "2  C_15651022          480   Male   44      10  129608.57              1   \n",
      "3  C_15797710          619   Male   29       4   98955.87              1   \n",
      "4  C_15573318          610   Male   26       8       0.00              2   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
      "0          1               0        141582.66       0  \n",
      "1          0               0         69228.20       1  \n",
      "2          1               0          5472.70       1  \n",
      "3          0               1        131712.51       0  \n",
      "4          1               0        166031.08       0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_data = train_data.head(500) # subsample 500 data points for faster demo\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    9000.000000\n",
      "mean        0.206444\n",
      "std         0.404776\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target = \"Exited\"\n",
    "print(\"Summary of class variable: \\n\", train_data[target].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to bankChurn-predictClass/\n",
      "Train Data Rows:    2612\n",
      "Train Data Columns: 11\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [0 1]\n",
      "AutoGluon infers your prediction problem is: binary  (because only two unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Feature Generator processed 2612 data points with 10 features\n",
      "Original Features:\n",
      "\tobject features: 2\n",
      "\tint features: 6\n",
      "\tfloat features: 2\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tobject features: 2\n",
      "\tint features: 6\n",
      "\tfloat features: 2\n",
      "\tData preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.7445\t = Validation accuracy score\n",
      "\t1.34s\t = Training runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.7405\t = Validation accuracy score\n",
      "\t1.55s\t = Training runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\t0.7585\t = Validation accuracy score\n",
      "\t0.93s\t = Training runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\t0.7485\t = Validation accuracy score\n",
      "\t0.99s\t = Training runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.491\t = Validation accuracy score\n",
      "\t0.02s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.523\t = Validation accuracy score\n",
      "\t0.02s\t = Training runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.7605\t = Validation accuracy score\n",
      "\t1.19s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.7725\t = Validation accuracy score\n",
      "\t1.54s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.7405\t = Validation accuracy score\n",
      "\t15.1s\t = Training runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.7665\t = Validation accuracy score\n",
      "\t6.89s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.7764\t = Validation accuracy score\n",
      "\t2.21s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.45s ...\n"
     ]
    }
   ],
   "source": [
    "dir = 'bankChurn-predictClass' # specifies folder where to store trained models\n",
    "predictor = task.fit(train_data=train_data, label=target, output_directory=dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c34a36dc63e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "# without directory parameter\n",
    "predictor = task.fit(train_data=train_data, label=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId    Surname  CreditScore Geography Gender  Age  \\\n",
      "0       9001    15723217  Cremonesi          616    France   Male   37   \n",
      "1       9002    15733111        Yeh          688     Spain   Male   32   \n",
      "2       9003    15610727      Ch'in          605    France   Male   36   \n",
      "3       9004    15792720   Martinez          676    France   Male   33   \n",
      "4       9005    15723153    Wearing          708     Spain   Male   33   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       9       0.00              1          1               0   \n",
      "1       6  124179.30              1          1               1   \n",
      "2       7  128829.25              1          1               0   \n",
      "3       6  171490.78              1          0               0   \n",
      "4       3       0.00              2          1               0   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        111312.96       0  \n",
      "1        138759.15       0  \n",
      "2        190588.59       0  \n",
      "3         79099.64       0  \n",
      "4        138613.21       0  \n"
     ]
    }
   ],
   "source": [
    "y_test = test_data[target]  # values to predict\n",
    "#test_data_nolab = test_data.drop(labels=[label_column],axis=1) # delete label column to prove we're not cheating\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    654.000000\n",
      "mean       0.500000\n",
      "std        0.500383\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.500000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary of class variable: \\n\", test_data[target].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.813\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.813,\n",
      "    \"accuracy_score\": 0.813,\n",
      "    \"balanced_accuracy_score\": 0.8074803176396137,\n",
      "    \"matthews_corrcoef\": 0.51745119593096,\n",
      "    \"f1_score\": 0.813\n",
      "}\n",
      "Detailed (per-class) classification report:\n",
      "{\n",
      "    \"0\": {\n",
      "        \"precision\": 0.9490084985835694,\n",
      "        \"recall\": 0.8160779537149817,\n",
      "        \"f1-score\": 0.8775376555337261,\n",
      "        \"support\": 821\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"precision\": 0.48639455782312924,\n",
      "        \"recall\": 0.7988826815642458,\n",
      "        \"f1-score\": 0.6046511627906976,\n",
      "        \"support\": 179\n",
      "    },\n",
      "    \"accuracy\": 0.813,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.7177015282033493,\n",
      "        \"recall\": 0.8074803176396137,\n",
      "        \"f1-score\": 0.7410944091622118,\n",
      "        \"support\": 1000\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.8662006031874506,\n",
      "        \"recall\": 0.813,\n",
      "        \"f1-score\": 0.8286909733327239,\n",
      "        \"support\": 1000\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1\n",
      " 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1\n",
      " 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = predictor.predict(test_data)\n",
    "print(\"Predictions:  \", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    RowNumber  CustomerId         Surname  CreditScore Geography  Gender  Age  \\\n",
      "90       9091    15813911  Hayes-Williams          809    France  Female   39   \n",
      "\n",
      "    Tenure  Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "90       5      0.0              1          1               0   \n",
      "\n",
      "    EstimatedSalary  Exited  \n",
      "90         77705.75       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/features/abstract_feature_generator.py:171: UserWarning: The columns listed below from the training data are no longer in the given dataset. (AutoGluon will proceed assuming their values are missing, but you should remove these columns from training dataset and train a new model):  ['PID', 'ST_NUM', 'ST_NAME', 'ST_NAME_SUF', 'ZIPCODE', 'Lot_Area', 'Gross_Area', 'Living_Area', 'Owner_Occupied', 'Year_Built', 'Number_of_Floors', 'Total_Number_of_Rooms', 'Number_of_Bedrooms', 'Number_of_Full_Baths', 'Number_of_Half_Baths', 'Number_of_Kitchens', 'Has_AC', 'Number_of_Fireplaces', 'Year_Since_Remodel_or_Build', 'Year_Remodeled', 'Structure_Type', 'Building_Style', 'Roof_Type', 'Exterior_Finish', 'Main_Bathroom_Style', 'Main_Kitchen_Style', 'Heating_type', 'Exterior_Condition', 'Overall_Condition', 'Interior_Condition', 'Interior_Finish', 'View']\n",
      "  \"from training dataset and train a new model):  %s\" % missing_cols)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot setitem on a Categorical with a new category, set the categories first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5a70ad0d73d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatapoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/task/tabular_prediction/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, dataset, model, as_pandas, use_pred_cache, add_to_pred_cache)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m    102\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_pandas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pred_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_pred_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_to_pred_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_to_pred_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/learner/abstract_learner.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test, model, as_pandas, sample, use_pred_cache, add_to_pred_cache)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_cache_miss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test_cache_miss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_problem_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mproblem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_problem_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/learner/abstract_learner.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X_test, model, as_pandas, inverse_transform, sample)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_cleaner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_best\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_best_core\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_best_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mpredict_proba_model\u001b[0;34m(self, X, model, level_start)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0mEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-10\u001b[0m \u001b[0;31m# predicted probabilities can be at most this confident if we normalize predicted probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# TODO: ensure each model always outputs appropriately normalized predictions so this final safety check then becomes unnecessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mget_inputs_to_model\u001b[0;34m(self, model, X, level_start, fit, preprocess)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_level\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs_to_stacker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_level\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/models/ensemble/stacker_ensemble_model.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, X, preprocess, fit, compute_base_preds, infer, model)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moof_pred_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mX_stacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: This could get very large on a high class count problem. Consider capping to top N most frequent classes and merging least frequent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mX_stacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_probas_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_stacker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/models/tabular_nn/tabular_nn_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, preprocess)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_tabular_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X must be of type pd.DataFrame or TabularNNDataset, not type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/models/tabular_nn/tabular_nn_model.py\u001b[0m in \u001b[0;36m_predict_tabular_data\u001b[0;34m(self, new_data, process, predict_proba)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \"\"\"\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dataloading_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloading_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTabularNNDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new_data must of of type TabularNNDataset if process=False\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/models/tabular_nn/tabular_nn_model.py\u001b[0m in \u001b[0;36mprocess_test_data\u001b[0;34m(self, df, batch_size, num_dataloading_workers, labels)\u001b[0m\n\u001b[1;32m    480\u001b[0m            or self.feature_arraycol_map is None or self.feature_type_map is None):\n\u001b[1;32m    481\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Need to process training data before test data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_onehot_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 2D numpy array. self.feature_arraycol_map, self.feature_type_map have been previously set while processing training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         return TabularNNDataset(df, self.feature_arraycol_map, self.feature_type_map,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/models/tabular_nn/tabular_nn_model.py\u001b[0m in \u001b[0;36mensure_onehot_object\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes_of_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'onehot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'object'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m                 \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    538\u001b[0m                     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplane_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlplane_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 ):\n\u001b[0;32m--> 540\u001b[0;31m                     \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;31m# per label values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36msetter\u001b[0;34m(item, v)\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"setitem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0mcheck_setitem_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1837\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_add\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m             raise ValueError(\n\u001b[0;32m-> 2190\u001b[0;31m                 \u001b[0;34m\"Cannot setitem on a Categorical with a new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m                 \u001b[0;34m\"category, set the categories first\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot setitem on a Categorical with a new category, set the categories first"
     ]
    }
   ],
   "source": [
    "datapoint = test_data.iloc[[90]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
    "print(datapoint)\n",
    "print(predictor.predict(datapoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57208657]\n"
     ]
    }
   ],
   "source": [
    "dir = 'bankChurn-predictClass'\n",
    "predictor = task.load('bankChurn-predictClass')\n",
    "class_probs = predictor.predict_proba(datapoint)\n",
    "print(class_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         model  score_test  score_val   fit_time  pred_time_test_full  pred_time_test  pred_time_val  stack_level\n",
      "0      weighted_ensemble_k0_l1       0.813   0.776447   2.206108             1.407308        0.012876       0.003826            1\n",
      "1     LightGBMClassifierCustom       0.809   0.766467   6.888336             0.053855        0.053855       0.026065            0\n",
      "2   RandomForestClassifierEntr       0.798   0.740519   1.546210             0.219588        0.219588       0.222393            0\n",
      "3           LightGBMClassifier       0.796   0.760479   1.186644             0.021938        0.021938       0.029017            0\n",
      "4           CatboostClassifier       0.791   0.772455   1.540292             0.016143        0.016143       0.023938            0\n",
      "5   RandomForestClassifierGini       0.777   0.744511   1.339774             0.222848        0.222848       0.221787            0\n",
      "6     ExtraTreesClassifierGini       0.776   0.758483   0.927002             0.221549        0.221549       0.225580            0\n",
      "7     ExtraTreesClassifierEntr       0.770   0.748503   0.990466             0.214522        0.214522       0.223102            0\n",
      "8          NeuralNetClassifier       0.766   0.740519  15.098509             0.185912        0.185912       0.145318            0\n",
      "9     KNeighborsClassifierDist       0.595   0.522954   0.023599             0.117669        0.117669       0.125669            0\n",
      "10    KNeighborsClassifierUnif       0.551   0.491018   0.022117             0.120408        0.120408       0.118193            0\n"
     ]
    }
   ],
   "source": [
    "results = predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from ExtraTreesClassifierGini model: [1]\n"
     ]
    }
   ],
   "source": [
    "i = 2  # index of model to use\n",
    "model_to_use = predictor.model_names[i]\n",
    "model_pred = predictor.predict(datapoint, model=model_to_use)\n",
    "print(\"Prediction from %s model: %s\" % (model_to_use, model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.813\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.813,\n",
      "    \"accuracy_score\": 0.813,\n",
      "    \"balanced_accuracy_score\": 0.8074803176396137,\n",
      "    \"matthews_corrcoef\": 0.51745119593096,\n",
      "    \"f1_score\": 0.813\n",
      "}\n",
      "Detailed (per-class) classification report:\n",
      "{\n",
      "    \"0\": {\n",
      "        \"precision\": 0.9490084985835694,\n",
      "        \"recall\": 0.8160779537149817,\n",
      "        \"f1-score\": 0.8775376555337261,\n",
      "        \"support\": 821\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"precision\": 0.48639455782312924,\n",
      "        \"recall\": 0.7988826815642458,\n",
      "        \"f1-score\": 0.6046511627906976,\n",
      "        \"support\": 179\n",
      "    },\n",
      "    \"accuracy\": 0.813,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.7177015282033493,\n",
      "        \"recall\": 0.8074803176396137,\n",
      "        \"f1-score\": 0.7410944091622118,\n",
      "        \"support\": 1000\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.8662006031874506,\n",
      "        \"recall\": 0.813,\n",
      "        \"f1-score\": 0.8286909733327239,\n",
      "        \"support\": 1000\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('accuracy', 0.813),\n",
       "             ('accuracy_score', 0.813),\n",
       "             ('balanced_accuracy_score', 0.8074803176396137),\n",
       "             ('matthews_corrcoef', 0.51745119593096),\n",
       "             ('f1_score', 0.813),\n",
       "             ('<lambda>',\n",
       "              {'0': {'precision': 0.9490084985835694,\n",
       "                'recall': 0.8160779537149817,\n",
       "                'f1-score': 0.8775376555337261,\n",
       "                'support': 821},\n",
       "               '1': {'precision': 0.48639455782312924,\n",
       "                'recall': 0.7988826815642458,\n",
       "                'f1-score': 0.6046511627906976,\n",
       "                'support': 179},\n",
       "               'accuracy': 0.813,\n",
       "               'macro avg': {'precision': 0.7177015282033493,\n",
       "                'recall': 0.8074803176396137,\n",
       "                'f1-score': 0.7410944091622118,\n",
       "                'support': 1000},\n",
       "               'weighted avg': {'precision': 0.8662006031874506,\n",
       "                'recall': 0.813,\n",
       "                'f1-score': 0.8286909733327239,\n",
       "                'support': 1000}})])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                         model  score_val   fit_time  pred_time_val  stack_level\n",
      "10     weighted_ensemble_k0_l1   0.776447   2.206108       0.003826            1\n",
      "7           CatboostClassifier   0.772455   1.540292       0.023938            0\n",
      "9     LightGBMClassifierCustom   0.766467   6.888336       0.026065            0\n",
      "6           LightGBMClassifier   0.760479   1.186644       0.029017            0\n",
      "2     ExtraTreesClassifierGini   0.758483   0.927002       0.225580            0\n",
      "3     ExtraTreesClassifierEntr   0.748503   0.990466       0.223102            0\n",
      "0   RandomForestClassifierGini   0.744511   1.339774       0.221787            0\n",
      "1   RandomForestClassifierEntr   0.740519   1.546210       0.222393            0\n",
      "8          NeuralNetClassifier   0.740519  15.098509       0.145318            0\n",
      "5     KNeighborsClassifierDist   0.522954   0.023599       0.125669            0\n",
      "4     KNeighborsClassifierUnif   0.491018   0.022117       0.118193            0\n",
      "Number of models trained: 11\n",
      "Types of models trained:\n",
      "{'LGBModel', 'KNNModel', 'WeightedEnsembleModel', 'RFModel', 'CatboostModel', 'TabularNeuralNetModel'}\n",
      "Bagging used: False \n",
      "Stack-ensembling used: False \n",
      "Hyperparameter-tuning used: False \n",
      "User-specified hyperparameters:\n",
      "{'NN': {'num_epochs': 500}, 'GBM': {'num_boost_round': 10000}, 'CAT': {'iterations': 10000}, 'RF': {'n_estimators': 300}, 'XT': {'n_estimators': 300}, 'KNN': {}, 'custom': ['GBM']}\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/autogluon/utils/plots.py:141: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  binary\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon categorized the features as:  {'nlp': [], 'vectorizers': [], 'object': ['CustomerId', 'Gender'], 'int': ['CreditScore', 'Age', 'Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember'], 'float': ['Balance', 'EstimatedSalary']}\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon categorized the features as: \", predictor.feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSION - Boston Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../../sets/boston_housing_train.csv | Columns = 33 / 33 | Rows = 29998 -> 29998\n",
      "Loaded data from: ../../sets/boston_housing_test.csv | Columns = 33 / 33 | Rows = 520 -> 520\n"
     ]
    }
   ],
   "source": [
    "train_data = task.Dataset(file_path='../../sets/boston_housing_train.csv')\n",
    "test_data = task.Dataset(file_path='../../sets/boston_housing_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PID ST_NUM    ST_NAME ST_NAME_SUF ZIPCODE  Assessed_Value  \\\n",
      "0  2001658000_     43  STRATFORD          ST  02132_          963300   \n",
      "1  2001659000_     47  STRATFORD          ST  02132_          915600   \n",
      "2  2001660000_     53  STRATFORD          ST  02132_          911400   \n",
      "3  2001661000_     57  STRATFORD          ST  02132_          862500   \n",
      "4  2001662000_     61  STRATFORD          ST  02132_          789300   \n",
      "\n",
      "   Lot_Area  Gross_Area  Living_Area  Owner_Occupied  ...  Roof_Type  \\\n",
      "0     20897        7396         3887               1  ...        Hip   \n",
      "1      9856        6730         3566               1  ...        Hip   \n",
      "2      8415        6442         2843               1  ...      Gable   \n",
      "3      8333        6020         3558               1  ...        Hip   \n",
      "4      8232        5574         2978               1  ...      Gable   \n",
      "\n",
      "   Exterior_Finish  Main_Bathroom_Style  Main_Kitchen_Style  Heating_type  \\\n",
      "0            Vinyl               Modern              Modern    Forced Air   \n",
      "1       Wood Shake               Modern              Modern     Hot Water   \n",
      "2       Wood Shake          Semi-Modern              Modern     Hot Water   \n",
      "3       Wood Shake          Semi-Modern              Modern     Hot Water   \n",
      "4       Wood Shake               Modern              Modern     Hot Water   \n",
      "\n",
      "   Exterior_Condition  Overall_Condition  Interior_Condition  Interior_Finish  \\\n",
      "0             Average            Average             Average           Normal   \n",
      "1             Average            Average                Good           Normal   \n",
      "2                Good               Good                Good           Normal   \n",
      "3             Average            Average                Good           Normal   \n",
      "4             Average            Average                Good           Normal   \n",
      "\n",
      "      View  \n",
      "0  Average  \n",
      "1  Average  \n",
      "2  Average  \n",
      "3  Average  \n",
      "4  Average  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = train_data.head(500) # subsample 500 data points for faster demo\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    5.000000e+02\n",
      "mean     5.484567e+05\n",
      "std      1.555300e+05\n",
      "min      2.334000e+05\n",
      "25%      4.326250e+05\n",
      "50%      5.330500e+05\n",
      "75%      6.514500e+05\n",
      "max      1.085755e+06\n",
      "Name: Assessed_Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target = \"Assessed_Value\"\n",
    "print(\"Summary of class variable: \\n\", train_data[target].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to bostonHousing-predictClass/\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 33\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [963300 915600 911400 862500 789300 653300 692000 711900 642900 505000]\n",
      "AutoGluon infers your prediction problem is: regression  (because dtype of label-column == int and many unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 500 data points with 30 features\n",
      "Original Features:\n",
      "\tobject features: 16\n",
      "\tint features: 13\n",
      "\tfloat features: 1\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tobject features: 16\n",
      "\tint features: 13\n",
      "\tfloat features: 1\n",
      "\tData preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: root_mean_squared_error\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: root_mean_squared_error\n",
      "Fitting model: RandomForestRegressorMSE_STACKER_l0 ... Training model for up to 59.82s of the 59.82s of remaining time.\n",
      "\t-45406.6576\t = Validation root_mean_squared_error score\n",
      "\t5.93s\t = Training runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE_STACKER_l0 ... Training model for up to 52.54s of the 52.53s of remaining time.\n",
      "\t-41092.5079\t = Validation root_mean_squared_error score\n",
      "\t3.57s\t = Training runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif_STACKER_l0 ... Training model for up to 47.94s of the 47.94s of remaining time.\n",
      "\t-90365.4427\t = Validation root_mean_squared_error score\n",
      "\t0.17s\t = Training runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist_STACKER_l0 ... Training model for up to 47.12s of the 47.12s of remaining time.\n",
      "\t-89090.7939\t = Validation root_mean_squared_error score\n",
      "\t0.18s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor_STACKER_l0 ... Training model for up to 46.29s of the 46.29s of remaining time.\n",
      "\t-45862.4141\t = Validation root_mean_squared_error score\n",
      "\t6.67s\t = Training runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor_STACKER_l0 ... Training model for up to 39.29s of the 39.29s of remaining time.\n",
      "\tTime limit exceeded... Skipping CatboostRegressor_STACKER_l0.\n",
      "Fitting model: NeuralNetRegressor_STACKER_l0 ... Training model for up to 26.08s of the 26.08s of remaining time.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\tRan out of time, stopping training early.\n",
      "\t-102102.959\t = Validation root_mean_squared_error score\n",
      "\t24.15s\t = Training runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom_STACKER_l0 ... Training model for up to 0.97s of the 0.97s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\ttrain_set's l2: 2.20835e+10\ttrain_set's root_mean_squared_error: -148605\tvalid_set's l2: 2.5754e+10\tvalid_set's root_mean_squared_error: -160480\n",
      "\tTime limit exceeded... Skipping LightGBMRegressorCustom_STACKER_l0.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: weighted_ensemble_k0_l1 ... Training model for up to 59.82s of the 0.61s of remaining time.\n",
      "\t-38908.1362\t = Validation root_mean_squared_error score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.05s ...\n"
     ]
    }
   ],
   "source": [
    "dir = 'bostonHousing-predictClass' # specifies folder where to store trained models\n",
    "long_time=60\n",
    "predictor = task.fit(train_data=train_data, label=target, output_directory=dir, auto_stack=True, time_limits=long_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c34a36dc63e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "# without directory parameter\n",
    "predictor = task.fit(train_data=train_data, label=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4fcb34c8b466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaderboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/task/tabular_prediction/predictor.py\u001b[0m in \u001b[0;36mleaderboard\u001b[0;34m(self, dataset, silent)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[1;32m    199\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaderboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/learner/abstract_learner.py\u001b[0m in \u001b[0;36mleaderboard\u001b[0;34m(self, X, y, silent)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mleaderboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mleaderboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/learner/abstract_learner.py\u001b[0m in \u001b[0;36mscore_debug\u001b[0;34m(self, X, y, silent)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mmodel_names_core\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'core'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_names_core\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0mpred_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probas_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pred_probas_models_and_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_names_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_names_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                     \u001b[0mpred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_probas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/learner/abstract_learner.py\u001b[0m in \u001b[0;36mget_pred_probas_models_and_time\u001b[0;34m(self, X, trainer, model_names)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mpred_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_proba_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMULTICLASS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_func_expects_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;31m# Handles case where we need to add empty columns to represent classes that were not used for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mpred_proba_predictions\u001b[0;34m(self, models, X_test)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0mmodel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/models/tabular_nn/tabular_nn_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, preprocess)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_tabular_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X must be of type pd.DataFrame or TabularNNDataset, not type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/utils/tabular/ml/models/tabular_nn/tabular_nn_model.py\u001b[0m in \u001b[0;36m_predict_tabular_data\u001b[0;34m(self, new_data, process, predict_proba)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_net_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpreds_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = predictor.leaderboard(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PID ST_NUM ST_NAME ST_NAME_SUF ZIPCODE  Assessed_Value  Lot_Area  \\\n",
      "0  0600851000_     22  LORING          ST  02127_          482700      1263   \n",
      "1  0600852000_     20  LORING          ST  02127_          467600      1263   \n",
      "2  0600853000_     18  LORING          ST  02127_          539300      1263   \n",
      "3  0600854000_     16  LORING          ST  02127_          501900      1263   \n",
      "4  0600857000_     10  LORING          ST  02127_          488000      1579   \n",
      "\n",
      "   Gross_Area  Living_Area  Owner_Occupied  ...  Roof_Type  Exterior_Finish  \\\n",
      "0        2040         1320               1  ...       Flat       Wood Shake   \n",
      "1        2040         1320               0  ...       Flat            Vinyl   \n",
      "2        2040         1320               1  ...       Flat  Frame/Clapboard   \n",
      "3        2040         1320               1  ...       Flat       Wood Shake   \n",
      "4        2262         1509               1  ...       Flat            Vinyl   \n",
      "\n",
      "   Main_Bathroom_Style  Main_Kitchen_Style  Heating_type  Exterior_Condition  \\\n",
      "0          Semi-Modern         Semi-Modern     Hot Water             Average   \n",
      "1               Modern              Modern  Space Heater             Average   \n",
      "2          Semi-Modern              Modern     Hot Water                Good   \n",
      "3          Semi-Modern              Modern     Hot Water             Average   \n",
      "4          Semi-Modern         Semi-Modern     Hot Water             Average   \n",
      "\n",
      "   Overall_Condition  Interior_Condition  Interior_Finish     View  \n",
      "0            Average                Good           Normal  Average  \n",
      "1            Average             Average           Normal  Average  \n",
      "2               Good                Good           Normal  Average  \n",
      "3            Average             Average           Normal  Average  \n",
      "4            Average             Average           Normal  Average  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "y_test = test_data[target]  # values to predict\n",
    "#test_data_nolab = test_data.drop(labels=[label_column],axis=1) # delete label column to prove we're not cheating\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    5.200000e+02\n",
      "mean     5.449698e+05\n",
      "std      5.122109e+05\n",
      "min      1.671000e+05\n",
      "25%      2.936750e+05\n",
      "50%      4.235500e+05\n",
      "75%      5.786000e+05\n",
      "max      4.843600e+06\n",
      "Name: Assessed_Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary of class variable: \\n\", test_data[target].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: 457379.3351830388\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": 457379.3351830388,\n",
      "    \"mean_absolute_error\": 212382.93044165007,\n",
      "    \"explained_variance_score\": 0.21124324408854966,\n",
      "    \"r2_score\": 0.20110170196514587,\n",
      "    \"pearson_correlation\": 0.6911943157558857,\n",
      "    \"mean_squared_error\": 209195856252.47855,\n",
      "    \"median_absolute_error\": 139103.1938344858\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [458582.01202812 437725.02693101 525972.06758915 424755.40628631\n",
      " 419927.99508981 484758.41983765 425610.0178208  428055.8028675\n",
      " 451308.38418518 407810.21936164 532594.37276051 431007.84939023\n",
      " 508933.89245317 465342.65122756 444839.60019284 426056.66200514\n",
      " 452314.95514463 566938.44440675 470453.82249513 394393.87782333\n",
      " 460123.50784374 466663.01516487 410139.9755297  436680.61407763\n",
      " 523378.23554081 399398.32264286 401029.96858665 388890.29698703\n",
      " 406291.26116543 502657.66200246 519783.88496676 406604.82351352\n",
      " 414298.08567856 463002.4609701  498860.86679751 526080.19735518\n",
      " 467509.18781229 435159.06054325 424342.76248536 398835.16760617\n",
      " 537996.95348827 571413.6093876  586764.23894263 388285.22430554\n",
      " 392896.2310109  406949.53390917 397764.20137336 393330.53539172\n",
      " 402975.35307016 528208.65759836 390989.41046495 410678.39442413\n",
      " 427422.50022928 421476.11244778 407975.22508348 455766.71139073\n",
      " 538510.07288868 553915.82785666 404951.51198009 553868.05842635\n",
      " 643089.21030076 507587.45556583 505350.08666954 499281.37856049\n",
      " 496143.24125967 418454.06215647 636838.15494817 595926.59125397\n",
      " 440213.85912852 581118.41340389 490195.30961127 478241.8880872\n",
      " 414435.59798448 560459.12761093 469731.33244441 550988.8814474\n",
      " 493193.0809266  521071.36344613 463174.49129776 618240.75749215\n",
      " 529868.21082965 437019.89656303 513319.40737896 474904.95656539\n",
      " 509552.09613066 622010.1242605  390062.67765546 675307.46185888\n",
      " 482871.28436678 607235.72068407 524776.01790627 514930.46864261\n",
      " 564062.52164646 451556.70187945 557489.83291942 555451.90128192\n",
      " 574206.16413028 604330.15200238 444871.65071369 481250.3508545\n",
      " 376638.45690098 452963.6368594  418558.40804911 430413.00895377\n",
      " 529706.77136712 391571.44818283 452643.5984487  515726.66654682\n",
      " 598673.65261589 563353.52903449 429148.54755981 400266.39668474\n",
      " 470416.13123505 499029.44720978 475099.90214512 419571.98861639\n",
      " 459736.80062246 541574.95734853 427910.31466706 448163.48173169\n",
      " 431012.04426678 505782.5928339  416652.83319529 442838.32923869\n",
      " 466012.14773202 421712.32158459 547304.14397534 480014.76124982\n",
      " 677652.22084289 438797.24866296 445925.67199166 406435.15181348\n",
      " 658088.8053725  550521.78796486 667445.42035155 504324.95467671\n",
      " 500013.43906476 397599.11427896 408774.70465874 435713.48960872\n",
      " 410306.59546415 398079.50766315 443098.55864518 453005.56299459\n",
      " 461112.4065512  440469.60030017 443964.83485711 389968.90199885\n",
      " 401676.71227749 526244.83611078 439501.22138665 466069.17662373\n",
      " 446260.61661245 437931.69665238 394213.76156056 452306.12491383\n",
      " 433693.22299754 428279.11246007 410787.50201698 438367.18631921\n",
      " 378431.41684972 388587.94217354 367705.78284072 401458.36236452\n",
      " 377919.29131592 394793.34960506 455797.19542154 425451.65241242\n",
      " 453715.86186607 405149.25597199 418954.54245894 469155.73434366\n",
      " 459027.63479187 457472.91179351 439801.03613054 411253.31202371\n",
      " 508720.00581466 418021.26515571 432769.15363096 481200.7743501\n",
      " 403666.70800371 524069.23727685 450299.84528484 420479.87925225\n",
      " 606301.8252875  420555.50503715 515326.02133537 509283.13713855\n",
      " 486098.60952085 442916.6682983  523570.49594577 503447.82284206\n",
      " 506616.72932665 405552.97420379 404823.89135599 430858.42397397\n",
      " 408256.35635105 439291.25901485 443421.35948192 413554.97516557\n",
      " 448249.90459736 449226.66295818 480403.69126092 422272.79044711\n",
      " 391783.16542512 399238.53705533 376470.03595024 414287.48468578\n",
      " 460795.56531641 455420.4474136  423839.80691568 393251.5468484\n",
      " 474894.74468364 440576.86699052 538837.65641624 531166.03159895\n",
      " 428913.50336237 444938.03140257 481104.35842437 465832.89246769\n",
      " 394692.64020899 373869.00688653 384579.31372832 392453.31678382\n",
      " 434120.18831651 401679.7247108  478141.7886687  403272.4342612\n",
      " 584217.779596   533063.47857564 392462.4713158  476388.41031425\n",
      " 555693.05646222 442052.80697234 446848.4641474  429743.79446844\n",
      " 386918.68926082 381687.492596   467289.00085048 494321.852036\n",
      " 446505.25700871 445869.8062244  393433.47010144 412890.3983154\n",
      " 471026.54350859 470436.04281831 410036.95191619 385236.93315915\n",
      " 413495.6827616  400183.74722072 395281.85904668 427390.16917113\n",
      " 600165.56905806 476960.77000839 448227.60480891 459341.08738846\n",
      " 455242.86281692 452741.02837444 447738.01273253 419433.27636216\n",
      " 453113.19882594 425725.40228386 403741.7787854  409695.93456495\n",
      " 545194.26779603 427226.93176401 469652.37910066 463171.18584654\n",
      " 461983.07663627 413833.1780324  418994.76790061 513594.19211575\n",
      " 480772.49319255 461050.42950977 450689.04499368 493692.94217685\n",
      " 531025.35012376 560793.22968354 568672.88792882 518076.70596741\n",
      " 499800.06627476 451938.51585958 513603.42003835 411667.7745411\n",
      " 512916.32442905 507163.79028321 558803.99729442 399149.07023697\n",
      " 640889.84321405 520817.24567756 417007.32517786 455480.0109233\n",
      " 519238.70917627 465610.25495105 591992.04551373 595216.77969538\n",
      " 452442.06045482 475167.70270345 432583.34206509 402338.68891653\n",
      " 424890.04560648 419882.87305673 432158.81514261 469029.37487178\n",
      " 501493.96074052 546840.08355374 568894.97680705 440864.87273863\n",
      " 538789.98435363 500731.27806172 521041.06050494 407603.33079392\n",
      " 467853.9483776  467856.88474123 647263.69745853 587365.99969869\n",
      " 510749.43828452 417968.23333503 450131.91157695 466071.70071092\n",
      " 580844.24136944 476572.11353427 691262.7295446  696722.12342117\n",
      " 697450.36850317 514717.07497564 440596.41513438 462935.70782508\n",
      " 549805.07822944 607551.01461477 584153.21059388 576186.80884568\n",
      " 616792.61278007 616785.72096189 612910.68937532 620831.93505279\n",
      " 622195.60473878 625461.75584617 675489.59584719 582480.10945955\n",
      " 589376.4936548  650422.67973157 574219.31902006 589342.26751453\n",
      " 655189.34199589 631619.72868763 828527.58623225 524897.37221375\n",
      " 497578.36530392 446558.5514747  391584.70244764 470924.23406092\n",
      " 405954.3252827  398738.6560481  398671.98892752 627801.78050669\n",
      " 467937.55489659 453176.101118   548088.5816644  554793.06030006\n",
      " 410286.5540403  532102.24423869 483045.79212438 446575.41951585\n",
      " 398984.87077722 460668.43965359 500437.90586532 459858.0217316\n",
      " 457576.88543703 439093.46110754 526982.9067972  427942.16385258\n",
      " 453960.60379273 435727.20510055 533971.93816783 545298.98296207\n",
      " 437999.80244647 525005.68578199 561054.91288611 457730.98205553\n",
      " 505719.90449484 472527.02181219 491434.17391505 445519.35799738\n",
      " 386601.79915525 428331.00160542 470090.38422405 398221.21155855\n",
      " 442370.8716804  424386.0748024  419567.47547691 414606.3030624\n",
      " 439745.05133286 506534.18457069 519243.39849537 477708.67640868\n",
      " 474795.57653982 547737.7098212  452026.16247439 484203.3720485\n",
      " 534715.47560059 504607.72157256 579560.20941321 528498.69433993\n",
      " 521335.31152982 623484.54720925 551186.66161667 585294.6671875\n",
      " 550865.19757563 406280.2782454  417610.25209863 397883.31716873\n",
      " 563326.70595507 493176.09637439 403774.19132537 422313.2698248\n",
      " 443579.74920535 419886.03132281 467186.03882393 593438.04473613\n",
      " 640635.1584128  518803.04289684 442097.71295528 490636.84122248\n",
      " 613314.78258793 439842.18481952 473261.85184734 462250.35021191\n",
      " 478282.49747354 506209.47057194 477119.87791099 527290.5846248\n",
      " 541993.35543297 465003.8211428  590247.85477545 540129.97711041\n",
      " 485214.12779481 467532.67961295 487795.58432665 543553.68927265\n",
      " 541052.8165437  474837.16088405 467004.51466188 646526.73897877\n",
      " 601984.98753489 464646.08955695 461250.83805299 592155.21006365\n",
      " 648622.03455042 634486.14064432 464345.46353886 558490.74739627\n",
      " 491416.64110626 468353.09763634 719147.7061724  551836.32614224\n",
      " 526924.72824358 646134.79700528 517305.29428324 762400.51789546\n",
      " 642596.62683265 621681.94546342 429237.92847674 394367.53271414\n",
      " 566416.87407155 557901.37921666 599281.86304452 496521.18151023\n",
      " 624724.62937539 450131.45579468 479444.80290768 436305.77742425\n",
      " 438911.6518185  448545.88824322 619468.47896454 435839.63245922\n",
      " 426463.83557273 501035.65458422 657890.68892597 569735.73131129\n",
      " 584382.75569148 517539.77937639 524845.21700914 582807.16395825\n",
      " 774325.5280989  770039.00219798 615670.47604229 778770.40887877\n",
      " 661685.75242579 787980.0455571  801618.28171196 814548.20229049\n",
      " 695697.29518901 874330.27796659 854587.20403873 626499.17817666\n",
      " 570673.90780078 447473.04372312 551583.15455785 555912.79625123\n",
      " 847578.77449273 550349.61056451 430841.83349909 517478.7906589\n",
      " 434704.26768247 458309.98101936 455250.88997793 449229.55436651\n",
      " 415283.25904159 401852.56089137 409069.36660762 528925.35595417\n",
      " 374833.19992658 494677.12376949 489370.58543642 503573.50683381\n",
      " 476307.3496136  749842.71710751 804615.71018202 827144.21531615]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = predictor.predict(test_data)\n",
    "print(\"Predictions:  \", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                                 model      score_val   fit_time  pred_time_val  stack_level\n",
      "6              weighted_ensemble_k0_l1  -38908.136248   0.622376       0.002178            1\n",
      "1    ExtraTreesRegressorMSE_STACKER_l0  -41092.507925   3.572278       0.727922            0\n",
      "0  RandomForestRegressorMSE_STACKER_l0  -45406.657642   5.933729       0.882036            0\n",
      "4         LightGBMRegressor_STACKER_l0  -45862.414114   6.670380       0.254090            0\n",
      "3   KNeighborsRegressorDist_STACKER_l0  -89090.793926   0.175237       0.628035            0\n",
      "2   KNeighborsRegressorUnif_STACKER_l0  -90365.442742   0.174025       0.619300            0\n",
      "5        NeuralNetRegressor_STACKER_l0 -102102.959028  24.145437       0.614221            0\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_RF'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Stack-ensembling used: False \n",
      "Hyperparameter-tuning used: False \n",
      "User-specified hyperparameters:\n",
      "{'NN': {'num_epochs': 500}, 'GBM': {'num_boost_round': 10000}, 'CAT': {'iterations': 10000}, 'RF': {'n_estimators': 300}, 'XT': {'n_estimators': 300}, 'KNN': {}, 'custom': ['GBM']}\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/autogluon/utils/plots.py:141: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  regression\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon categorized the features as:  {'nlp': [], 'vectorizers': [], 'object': ['PID', 'ST_NUM', 'ST_NAME', 'ST_NAME_SUF', 'ZIPCODE', 'Year_Remodeled', 'Building_Style', 'Roof_Type', 'Exterior_Finish', 'Main_Bathroom_Style', 'Main_Kitchen_Style', 'Heating_type', 'Exterior_Condition', 'Overall_Condition', 'Interior_Condition', 'View'], 'int': ['Lot_Area', 'Gross_Area', 'Living_Area', 'Owner_Occupied', 'Year_Built', 'Total_Number_of_Rooms', 'Number_of_Bedrooms', 'Number_of_Full_Baths', 'Number_of_Half_Baths', 'Number_of_Kitchens', 'Has_AC', 'Number_of_Fireplaces', 'Year_Since_Remodel_or_Build'], 'float': ['Number_of_Floors']}\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon categorized the features as: \", predictor.feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_nolab = test_data.drop(labels=[target],axis=1) # delete label column to prove we're not cheating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PID ST_NUM ST_NAME ST_NAME_SUF ZIPCODE  Assessed_Value  Lot_Area  \\\n",
      "1  0600852000_     20  LORING          ST  02127_          467600      1263   \n",
      "\n",
      "   Gross_Area  Living_Area  Owner_Occupied  ...  Roof_Type  Exterior_Finish  \\\n",
      "1        2040         1320               0  ...       Flat            Vinyl   \n",
      "\n",
      "   Main_Bathroom_Style  Main_Kitchen_Style  Heating_type  Exterior_Condition  \\\n",
      "1               Modern              Modern  Space Heater             Average   \n",
      "\n",
      "   Overall_Condition  Interior_Condition  Interior_Finish     View  \n",
      "1            Average             Average           Normal  Average  \n",
      "\n",
      "[1 rows x 33 columns]\n",
      "[437725.02693101]\n"
     ]
    }
   ],
   "source": [
    "# SCORE/TEST 1 row\n",
    "datapoint = test_data.iloc[[1]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
    "print(datapoint)\n",
    "print(predictor.predict(datapoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSION - Walmart Baltimore Store 7 day lag forescasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../../sets/baltimore_store_univariate_7_lag.csv | Columns = 10 / 10 | Rows = 542 -> 542\n"
     ]
    }
   ],
   "source": [
    "df = task.Dataset(file_path='../../sets/baltimore_store_univariate_7_lag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../../sets/boston_housing_train.csv | Columns = 33 / 33 | Rows = 29998 -> 29998\n",
      "Loaded data from: ../../sets/boston_housing_test.csv | Columns = 33 / 33 | Rows = 520 -> 520\n"
     ]
    }
   ],
   "source": [
    "train_data = task.Dataset(file_path='../../sets/boston_housing_train.csv')\n",
    "test_data = task.Dataset(file_path='../../sets/boston_housing_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Store','Date','Lag_Sales_7_Day','Lag_Sales_6_Day','Lag_Sales_5_Day','Lag_Sales_4_Day','Lag_Sales_3_Day','Lag_Sales_2_Day','Lag_Sales_1_Day','Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(df)*.6)\n",
    "train_data = df[:n]\n",
    "test_data = df[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Store        Date  Lag_Sales_7_Day  Lag_Sales_6_Day  Lag_Sales_5_Day  \\\n",
      "0  Baltimore  2012-07-08          40669.0          35360.0          40741.0   \n",
      "1  Baltimore  2012-07-09          35360.0          40741.0          33871.0   \n",
      "2  Baltimore  2012-07-10          40741.0          33871.0          36880.0   \n",
      "3  Baltimore  2012-07-11          33871.0          36880.0          43441.0   \n",
      "4  Baltimore  2012-07-12          36880.0          43441.0          47133.0   \n",
      "\n",
      "   Lag_Sales_4_Day  Lag_Sales_3_Day  Lag_Sales_2_Day  Lag_Sales_1_Day    Sales  \n",
      "0          33871.0          36880.0          43441.0          47133.0  40165.0  \n",
      "1          36880.0          43441.0          47133.0          40165.0  37262.0  \n",
      "2          43441.0          47133.0          40165.0          37262.0  37718.0  \n",
      "3          47133.0          40165.0          37262.0          37718.0  35429.0  \n",
      "4          40165.0          37262.0          37718.0          35429.0  36206.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_data = train_data.head(500) # subsample 500 data points for faster demo\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count       325.000000\n",
      "mean      45276.433846\n",
      "std       17005.145728\n",
      "min           0.000000\n",
      "25%       35108.000000\n",
      "50%       40053.000000\n",
      "75%       48973.000000\n",
      "max      171345.000000\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target = \"Sales\"\n",
    "print(\"Summary of class variable: \\n\", train_data[target].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to walmartBaltimoreStoreSales-predictClass/\n",
      "Train Data Rows:    325\n",
      "Train Data Columns: 10\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [40165. 37262. 37718. 35429. 36206. 37865. 39216. 37190. 42122. 33963.]\n",
      "AutoGluon infers your prediction problem is: regression  (because dtype of label-column == float and many unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 325 data points with 8 features\n",
      "Original Features:\n",
      "\tdatetime features: 1\n",
      "\tfloat features: 7\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tdatetime features: 1\n",
      "\tfloat features: 7\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: root_mean_squared_error\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: root_mean_squared_error\n",
      "Fitting model: RandomForestRegressorMSE_STACKER_l0 ...\n",
      "\t-13649.2985\t = Validation root_mean_squared_error score\n",
      "\t4.75s\t = Training runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: ExtraTreesRegressorMSE_STACKER_l0 ...\n",
      "\t-13480.534\t = Validation root_mean_squared_error score\n",
      "\t2.89s\t = Training runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorUnif_STACKER_l0 ...\n",
      "\t-14379.1586\t = Validation root_mean_squared_error score\n",
      "\t0.07s\t = Training runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: KNeighborsRegressorDist_STACKER_l0 ...\n",
      "\t-13671.4621\t = Validation root_mean_squared_error score\n",
      "\t0.09s\t = Training runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor_STACKER_l0 ...\n",
      "\t-13509.1349\t = Validation root_mean_squared_error score\n",
      "\t1.79s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor_STACKER_l0 ...\n",
      "\t-13304.194\t = Validation root_mean_squared_error score\n",
      "\t3.83s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetRegressor_STACKER_l0 ...\n",
      "\t-24284.407\t = Validation root_mean_squared_error score\n",
      "\t10.23s\t = Training runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressorCustom_STACKER_l0 ...\n",
      "\t-13514.0561\t = Validation root_mean_squared_error score\n",
      "\t2.38s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-12937.3135\t = Validation root_mean_squared_error score\n",
      "\t0.81s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 30.55s ...\n"
     ]
    }
   ],
   "source": [
    "dir = 'walmartBaltimoreStoreSales-predictClass' # specifies folder where to store trained models\n",
    "#long_time=60\n",
    "#predictor = task.fit(train_data=train_data, label=target, output_directory=dir, auto_stack=True, time_limits=long_time)\n",
    "predictor = task.fit(train_data=train_data, label=target, output_directory=dir, auto_stack=True, num_bagging_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c34a36dc63e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "# without directory parameter\n",
    "#predictor = task.fit(train_data=train_data, label=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 model    score_test     score_val   fit_time  pred_time_test_full  pred_time_test  pred_time_val  stack_level\n",
      "0    ExtraTreesRegressorMSE_STACKER_l0  -2696.106798 -13480.533992   2.889692             0.742692        0.742692       0.560416            0\n",
      "1   KNeighborsRegressorDist_STACKER_l0  -2734.292427 -13671.462137   0.093644             0.541837        0.541837       0.606431            0\n",
      "2              weighted_ensemble_k0_l1  -6138.360561 -12937.313545   0.813812             3.670456        0.007282       0.001576            1\n",
      "3  RandomForestRegressorMSE_STACKER_l0  -6671.495997 -13649.298464   4.754896             0.727993        0.727993       0.556226            0\n",
      "4         CatboostRegressor_STACKER_l0  -7881.490656 -13304.193950   3.828852             0.019301        0.019301       0.031090            0\n",
      "5   LightGBMRegressorCustom_STACKER_l0  -9069.209284 -13514.056137   2.379548             0.179446        0.179446       0.031096            0\n",
      "6         LightGBMRegressor_STACKER_l0 -10694.385280 -13509.134916   1.788309             0.038132        0.038132       0.032492            0\n",
      "7   KNeighborsRegressorUnif_STACKER_l0 -11533.448209 -14379.158592   0.069541             0.544315        0.544315       0.574448            0\n",
      "8        NeuralNetRegressor_STACKER_l0 -21798.544094 -24284.406984  10.228454             0.869458        0.869458       0.249832            0\n"
     ]
    }
   ],
   "source": [
    "results = predictor.leaderboard(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Store        Date  Lag_Sales_7_Day  Lag_Sales_6_Day  Lag_Sales_5_Day  \\\n",
      "325  Baltimore  2013-05-29          32028.0          43032.0          38893.0   \n",
      "326  Baltimore  2013-05-30          43032.0          38893.0          94310.0   \n",
      "327  Baltimore  2013-05-31          38893.0          94310.0          61910.0   \n",
      "328  Baltimore  2013-06-01          94310.0          61910.0          68710.0   \n",
      "329  Baltimore  2013-06-02          61910.0          68710.0          33565.0   \n",
      "\n",
      "     Lag_Sales_4_Day  Lag_Sales_3_Day  Lag_Sales_2_Day  Lag_Sales_1_Day  \\\n",
      "325          94310.0          61910.0          68710.0          33565.0   \n",
      "326          61910.0          68710.0          33565.0          28092.0   \n",
      "327          68710.0          33565.0          28092.0          38618.0   \n",
      "328          33565.0          28092.0          38618.0          33682.0   \n",
      "329          28092.0          38618.0          33682.0          45300.0   \n",
      "\n",
      "       Sales  \n",
      "325  28092.0  \n",
      "326  38618.0  \n",
      "327  33682.0  \n",
      "328  45300.0  \n",
      "329  38835.0  \n"
     ]
    }
   ],
   "source": [
    "y_test = test_data[target]  # values to predict\n",
    "#test_data_nolab = test_data.drop(labels=[label_column],axis=1) # delete label column to prove we're not cheating\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count       217.000000\n",
      "mean      40454.682028\n",
      "std       12936.348597\n",
      "min           0.000000\n",
      "25%       32300.000000\n",
      "50%       36597.000000\n",
      "75%       45472.000000\n",
      "max      105102.000000\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary of class variable: \\n\", test_data[target].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: 13785.64524221618\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": 13785.64524221618,\n",
      "    \"mean_absolute_error\": 11775.423034662634,\n",
      "    \"explained_variance_score\": 0.29937623837798055,\n",
      "    \"r2_score\": -0.14087157322906774,\n",
      "    \"pearson_correlation\": 0.6574891573005974,\n",
      "    \"mean_squared_error\": 190044014.7442376,\n",
      "    \"median_absolute_error\": 12100.389598650996\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [45296.93401306 46783.29295454 49393.53795989 48186.60813497\n",
      " 48222.57088871 54388.46281231 45914.80595644 45613.63988749\n",
      " 48390.62889188 47289.17637379 49229.87421143 48582.8663592\n",
      " 47459.65913446 46152.62577786 45667.36508223 46837.72036527\n",
      " 47266.31213991 51229.58499398 53107.66981993 46873.14442734\n",
      " 45165.35393289 46038.80783692 46583.12583803 48013.95864907\n",
      " 47419.7544108  49033.84167651 46624.50749108 47452.54754126\n",
      " 46321.5887908  46896.79579559 46117.49322471 49677.13272725\n",
      " 46648.42738686 47243.52565079 45849.29874845 46499.40884424\n",
      " 45428.51711531 47187.55386629 49487.44583892 50250.62147583\n",
      " 47129.25444691 48367.47286221 46149.59545282 49233.45791093\n",
      " 46599.05510047 48443.41715795 49534.03579261 48071.45631868\n",
      " 51218.79668241 46550.66803782 47595.54430004 45987.80686537\n",
      " 47504.14623541 46035.88287377 48074.66421646 48827.8282215\n",
      " 47230.57611791 47478.65754861 46711.79913768 48401.18709516\n",
      " 47474.7890189  45661.88300313 47418.88294129 46483.1657609\n",
      " 46914.1305288  46408.20688525 50682.42484977 47039.45071311\n",
      " 45876.58132819 46426.56378709 44742.92854271 48450.93196811\n",
      " 45815.19787284 47525.68673232 46966.50745415 46577.74324934\n",
      " 44849.24065309 48231.69495141 48053.86308765 49176.70522861\n",
      " 46936.62255971 48729.58824496 45950.27042663 46812.07809445\n",
      " 45649.89571461 46942.67154282 46061.99498257 47568.269633\n",
      " 46213.916511   46367.55002    45360.19721308 45743.1939409\n",
      " 47705.49248305 47276.92788814 46848.91244595 45854.37540546\n",
      " 47024.49153198 46474.5686118  47890.35712532 45883.48055919\n",
      " 46043.9479133  46610.93622101 47204.89022517 46593.03827142\n",
      " 45389.78103334 46612.80001427 47735.12437183 48889.3369012\n",
      " 54325.52332426 46582.69628181 45631.49852999 46551.71309527\n",
      " 48319.79402054 49162.78505894 49525.73972374 46618.52063646\n",
      " 47462.38662865 47016.36592751 45420.30756399 46672.99123194\n",
      " 46951.78985479 46166.03360027 49483.04525117 46416.04138744\n",
      " 47083.78016575 45294.93386814 45757.61463225 45768.02833023\n",
      " 48217.42769565 48168.17107373 46357.05502915 45994.69212761\n",
      " 45132.85519985 45808.16799973 47929.01811744 46372.79858381\n",
      " 50931.05682987 56615.7334007  55115.68032917 49294.60202072\n",
      " 45592.37109595 44849.2998735  48965.43200004 48137.40440328\n",
      " 47295.02199262 49988.93763368 45751.24742075 46262.991001\n",
      " 47632.42531403 48205.64321304 46724.16071911 46126.17631314\n",
      " 46441.03508171 45728.76965171 47998.94377281 47845.87509642\n",
      " 46413.87385313 48503.86001373 48293.31110559 46541.56825481\n",
      " 46374.0976179  46846.25770112 46643.19515962 50094.50868117\n",
      " 51703.47528474 58078.74040373 57445.49077241 45547.60887007\n",
      " 45947.472638   48970.76264384 58270.84695742 59500.71303581\n",
      " 50963.80099668 52884.57758514 53181.47028863 48056.94354099\n",
      " 49281.61456708 49839.56140369 52803.19176615 56852.77332337\n",
      " 49575.14507628 48414.88191862 51884.63394989 53174.90302631\n",
      " 59055.61910238 61373.67546438 54040.34947725 47975.82193559\n",
      " 51863.45906411 57508.75343908 60371.12495782 56972.20667956\n",
      " 53882.61040135 55614.99110942 53969.90979893 51691.13854582\n",
      " 53699.72490448 54016.39369798 53949.52191507 58183.9931455\n",
      " 59851.52341728 58301.08361903 49607.77000558 53396.4677072\n",
      " 54614.03708734 62469.42920139 56645.86978306 56773.90583502\n",
      " 56136.02843766 55699.26048411 53562.69162364 52588.08080941\n",
      " 49941.82289728 55391.03892562 53475.80085693 53854.84446178\n",
      " 52585.6677521 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = predictor.predict(test_data)\n",
    "print(\"Predictions:  \", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                                 model     score_val   fit_time  pred_time_val  stack_level\n",
      "8              weighted_ensemble_k0_l1 -12937.313545   0.813812       0.001576            1\n",
      "5         CatboostRegressor_STACKER_l0 -13304.193950   3.828852       0.031090            0\n",
      "1    ExtraTreesRegressorMSE_STACKER_l0 -13480.533992   2.889692       0.560416            0\n",
      "4         LightGBMRegressor_STACKER_l0 -13509.134916   1.788309       0.032492            0\n",
      "7   LightGBMRegressorCustom_STACKER_l0 -13514.056137   2.379548       0.031096            0\n",
      "0  RandomForestRegressorMSE_STACKER_l0 -13649.298464   4.754896       0.556226            0\n",
      "3   KNeighborsRegressorDist_STACKER_l0 -13671.462137   0.093644       0.606431            0\n",
      "2   KNeighborsRegressorUnif_STACKER_l0 -14379.158592   0.069541       0.574448            0\n",
      "6        NeuralNetRegressor_STACKER_l0 -24284.406984  10.228454       0.249832            0\n",
      "Number of models trained: 9\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_Catboost', 'StackerEnsembleModel_TabularNeuralNet', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_LGB'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Stack-ensembling used: False \n",
      "Hyperparameter-tuning used: False \n",
      "User-specified hyperparameters:\n",
      "{'NN': {'num_epochs': 500}, 'GBM': {'num_boost_round': 10000}, 'CAT': {'iterations': 10000}, 'RF': {'n_estimators': 300}, 'XT': {'n_estimators': 300}, 'KNN': {}, 'custom': ['GBM']}\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/autogluon/utils/plots.py:141: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  regression\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon categorized the features as:  {'nlp': [], 'vectorizers': [], 'datetime': ['Date'], 'float': ['Lag_Sales_7_Day', 'Lag_Sales_6_Day', 'Lag_Sales_5_Day', 'Lag_Sales_4_Day', 'Lag_Sales_3_Day', 'Lag_Sales_2_Day', 'Lag_Sales_1_Day'], 'int': []}\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon categorized the features as: \", predictor.feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_nolab = test_data.drop(labels=[target],axis=1) # delete label column to prove we're not cheating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Store        Date  Lag_Sales_7_Day  Lag_Sales_6_Day  Lag_Sales_5_Day  \\\n",
      "541  Baltimore  2013-12-31          54615.0              0.0          50458.0   \n",
      "\n",
      "     Lag_Sales_4_Day  Lag_Sales_3_Day  Lag_Sales_2_Day  Lag_Sales_1_Day  \\\n",
      "541          52986.0          53680.0          58826.0          47531.0   \n",
      "\n",
      "       Sales  \n",
      "541  45472.0  \n",
      "[52585.6677521]\n"
     ]
    }
   ],
   "source": [
    "# SCORE/TEST 1 row\n",
    "datapoint = test_data.iloc[[216]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
    "print(datapoint)\n",
    "print(predictor.predict(datapoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
